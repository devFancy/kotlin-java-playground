# '요즘 당근 AI 개발' 책 정리

당근 - 더 나은 사용자 경험을 위해 누구든 자신의 자리에서 실험하고 제안할 수 있는 문화를 지향한다.


---

## 인상깊게 봤던 부분 & 배운 점

- 프롬프트 엔지니어링이 무엇이고 어떻게 서비스에 적용해야하는지 알려주는 책이었다.
- 사용자 경험이 중요한 LLM 중심 서비스에는 프롬프팅에 UX가 충분히 반영되어야 한다.
    - 사용자들의 말투, 절대 사용해지 말아야 할 표현, 반드시 포함해야 할 정보, 글의 구조
- ‘사용자 중심의 사고’를 기반으로 완벽을 추구하기 보다는 빠른 학습과 반복적인 실험을 하자.
- 프롬프트 설계 → `일관성과` `맥락 해석`이 중요하다.
- 바이브 코딩 (~p.28)
    - AI 도구들이 발전하면서 이제는 머릿속에 있는 아이디어들이 직접 구현할 수 있는 가능성으로 바뀌었다.
- AI 글쓰기 프롬프팅 실전 전략 (p.47) (구글에서 제공하는 프롬프팅 가이드 문서 참고함)
    - 논리적 구조 설계(입출력) → 마크다운 기반 프롬프트 작성 (+예시 2-3개 포함) → 프롬프팅에 중간 과정 및 결과물을 함께 출력한다.
- GPT를 사용한 리뷰 자동화 시스템 구축기 (p.56)
    - 고객 피드백 → 제품이나 서비스 개선 → 고객 신뢰 쌓기 → 장기적인 충성도 확보 → 브랜드 명성 구축
    - 왜 도입했는가 → 반복적인 수 작업을 자동화하기 위함
    - GPT가 리뷰 요약 → 슬랙 채널 → 각 서비스별 담당자가 확인
    - 자동화: 리뷰 요약 → 리뷰 라벨링 → VoC 분석 리포트 (인사이트, 스프레드시트 정리)
- 작은 팀, LLM으로 큰 업무효율 내기 (p.93)
    - (사전에 MCP 기본 아키텍처 및 사용해봐야 함)
    - Sentry: 에러 상황 신속 파악(p.105) → MCP가 해당 에러의 상세 정보를 가져오고, 필요하면 서버로그 MCP와 연계해서 분석 및 수행 → 에러 원인 및 해결 방법을 제시
    - 실전사례 2: 에러 실시간 분석 ‘에러박사’ (p.115 ~ p.124)
        - 목표 두 가지: 에러의 중요도 자동 판단, 초기 대응 시간 단축
        - 에러 메시지 + 서버 로그/코드 → 전체적인 맥락 파악
- LLM에게 정확하고 세밀한 정보를 제공할수록 원하는 출력 결과를 가진다. (p.134-135)
    - 특정 오류가 반복된다면 → few-shot 기법 사용한다.
    - 입력 문장및 기대 출력 결과를 한 쌍으로 보여준다.
    - 명확한 오류가 반복되거나, 규칙만으로 해결이 어려울 때 이 기법을 사용한다.
    - 당근의 경우 JSON 형식의 구조화된 출력으로 고정함
    - LLM이 오류를 출력할 때 왜 틀렸는지 고민하고 그 이유를 기준에 반영하여 레슨런에 축적한다.
- LLM으로 복잡한 게시글을 구조화하기 (p.137-8) - LLM이 일하는 도구가 되려면 아래 3가지 질문에 명확히 답해야 한다.
    - 이 서비스 혹은 문제에서, 우리가 얻고자 하는 정보가 무엇인가?
    - 그 정보를 어떤 기준으로 판단하는가?
    - 그 기준이 모델이 이해할 수 있도록 구조화하여 설명했는가?
- VoC 플레이그라운드로 고객 목소리에 반응하는 당근 만들기
    - 사용자 의견을 수집하는 작업 + 사용자의 의견을 분석하고 활용하는 작업
    - AI 로 데이터 정리 → 문제점: 미리 정의된 분류 체계로 내 관심사를 맞추어야 하는 역설적인 상황 발생
    - 이를 해결하고자 사용자의 질문, 관심사에 기반한 동적 필터링 필요 + 실질적인 인사이트를 도출하고 공유할 수 있어야 함
    - 팀 관련 데이터만 분류할 수 있도록 VoC 플레이그라운드 고안
        - 데이터 소스와 필터 중심으로 데이터파이프라인 설계
    - 분류된 사용자 의견으로 보고서 만들기 → LLM 활용
        - 목적에 맞는 프롬프트를 작성해 데이터를 분석 (e.g. 최근 일주일간 ~ 사용하면서 사용자가 가장 자주 언급한 불편사항 3가지가 뭐야?)
        - 필요에 따라 질문의 각도를 다르게 설정 → 데이터를 다양한 관점에서 탐색 (e.g. 가장 긴급히 개선이 필요한 문제점 두 가지와 그 이유를 사용자 의견 기반으로 설명해줘)
    - 보고서를 활용하여 정기 보고서 만들기
        - 주기적으로 자동화하여 각 팀이 매일, 매주, 매월 원하는 주기에 맞춰 핵심 인사이트가 담긴 보고서를 받게 하기
        - 시간 흐름에 따른 변화를 추적할 수 있도록 하기 → 특정 기능 업데이트 하면 이후 사용자 의견에 어떻게 반영되는지 추적하여 인사이트 도출하기
    - VoC 플레이그라운드의 아쉬운점 및 개선점
        - 특정 기간/특정 카테고리로 범위를 제한하지 말고 여러 서비스 영역을 아울러서 대규모 데이터셋을 분석하여 포괄적인 인사이트 도출
        - LLM 분석 결과에 대한 신뢰성 확보 → 데이터가 많아질 수록 결과의 정확성, 신뢰도 중요
- 모든 당근 사용자에게 AI 에이전트 제공하기 - 1부 (이론적 토대 기반으로 멀티 AI 에이전트 구축)
    - 직접 만든 AI 에이전트 시스템 KAMP(Karrot Agent Management Platform) 구상하기
    - 우리 니즈에 딱 맞는 우리만의 플랫폼 구축 → 각 에이전트 별로 모델(Claude, GPT, Gemini) 구성
    - 노코드/로우코드 → 에이전트생성 시 각 역할, 설명, 모델 제공자(OpenAI), 모델(GPT-4o), 프롬프트 작성
    - 도구 템플릿이라는 개념 설계 → 여러 타입(REST API, gPRC, MCP) 지정
    - 에이전트에게 데이터를 제공할 때 주의해야할 사항
        - 개인 정보는 모두 마스킹 처리해야하며 사내 보안정책에 맞게 저장되도록 해야 함
    - KAMP에서 에이전트 오케스트레이션하기
        - 멀티 에이전트 → 서로 다른 에이전트가 협업하기 위해서는 서로 어떤 전문성을 가지고 있는지, 무슨 문제를 해결하는지 인지하도록 만들어야 함
        1. 에이전트간 상호 인식 → 에이전트 디스크립션에 상세히 정의(역할, 해결 가능한 문제 유형, 사용 방법, 출력 형태)
        2. 명확한 소통 체계 → 구조화된 통신을 통해 커뮤니케이션의 기본 구조를 정의(입력/출력 스키마)
- 모든 당근 사용자에게 AI 에이전트 제공하기 - 2부(당근만의 특화 기능 구현 → 사용자의 문제 해결 경험)
    - 에이전트 진행 사항 알려주기 → 민감한 정보는 마스킹 처리, 사전에 정의된 메시지를 보여주기 (e.g. 관련된 운영정책을 찾고 있어요 …)
    - RAG 를 통해 당근 내부 정보를 검색하기
        - RAG: 에이전트가 답변을 생성할 때 실시간으로 외부 문서나 (내부 지식) 데이터베이스에서 관련 정보를 검색해서 참조하는 기술 → 부정확한 답변에 대한 문제를 해결할 수 있음
    - 당근 AI 에이전트 만들기 → 정책 기준을 가지고 멀티 에이전트를 활용 → 병렬로 호출함으로써 성능 개선
- 바이브 코딩 프롬프트 팁 - 부록 A
    - 코드 의심하기 (아래는 예시)
        - 지금까지 생성한 코드 전체를 검토해줘
            - 비효율적인 쿼리나 반복 계산이 있는지
            - 중복되는 함수나 변수가 있는지
            - 사용하지 않는 라이브러리나 import가 되어 있는지
    - 검토 요청
        - 현재 코드보다 더 효율적으로 처리할 수 있는 방법이 있다면 알려줘. 성능, 가독성, 유지보수 측면에서 개선 가능성이 있는 부분이 있는지도 함께 설명해줘.
        - 보안적으로 문제가 될 수 있는 코드가 포함되어 있는지 확인해줘. 입력 검증 부족, 하드코딩된 비밀번호, 외부 요청 처리 등 기본적인 취약점이 있는지도 점검해줘.
- 성공적인 에이전트 팁 5가지 - 부록 B
    - 사용자 경험을 챙겨라
        - 여러 에이전트가 협업하더라도 사용자가 느끼기에 하나의 일관된 대화 상태와 소통한다고 느껴야 한다. 가이드 문서를 LLM이 이해할 수 있는 형태로 가공하고 프롬프트에 녹여내는데 시간과 노력이 필요하다.
        - 에이전트 실행 중 CoT(Chain-of-Thought) 를 제공할 방법을 고민해야 한다. 복잡한 문제 해결 과정에서 에이전트가 어떤 단계를 거쳐 추론하는지 사용자에게 보여주면 신뢰도를 높일 수 있다.
        - 무엇보다도 레이턴시 견딜 수 있는 UI를 고려해야 한다.
    - 할루시네이션을 해결하라
        - 연쇄적 오류를 일으킬 위험을 방지하기 위해 RAG 기법을 사용해야 한다.
        - 벡터 데이터베이스에 공식 문서, 운영 가이드라인, 최신 정책 자료를 임베딩하여 저장 → 실시간으로 가장 관련성 높은 정보를 추출해 답변 생성에 활용
        - 구조화된 에이전트 통신을 구현하는 것도 핵심.
    - AI 에이전트와 다른 시스템의 협업
        - AI 에이전트가 스스로 해결할 수 있는 범위와 인간의 개입이 필요한 지점을 명확히 구분하자.
        - 1차는 AI 에이전트 → 2차 인간 개입
    - 보안과 프롬프트 방어 설계
        - 개인정보 유출 시도, 시스템 명령어 주입, 부적절한 콘텐츠 생성 등 → 거부 기준을 세우고 프롬프트에 반영해야 한다.
        - 보안 → 세 가지 원칙
            - 사용자의 민감한 데이터 제공 X, MCP 서버를 통해 데이터를 받음
            - KAMP 데이터를 보관하는 DB는 개인 정보 DB로 분류하고 권한 없이 데이터 변경, 추출할 수 없도록 강제함.
            - KAMP 어드민의 접근 권한을 제어 → 신청 후 보안팀의 승인절차를 거친 구성원만 접근하도록 함.
    - 레이턴시를 해결하라
        - 변동성이 적은 내부 지식은 빠르게 조회하도록 캐싱 전략을 사용한다.
        - LLM 모델 자체도 응답 속도와 정확도의 균형을 맞출 수 있도록 다양한 모델을 테스트하고 적용하는 전략도 필요하다.
